<!doctype html>
<html>

<head>
    <title>LLM Tokenizer</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" type="image/svg+xml" href="favicons/token.svg" />
    <link href="tokenizer.css" rel="stylesheet">
</head>

<body>
    <a href="https://www.danieldemmel.me">â†© Back to danieldemmel.me</a>
    <!-- TODO: add link to Github -->
    <h1><img src="favicons/token.svg" alt="Token"><img src="favicons/token.svg" alt="Token"><img
            src="favicons/token.svg" alt="Token"><span>Online LLM Tokenizer</span><img src="favicons/token.svg"
            alt="Token"><img src="favicons/token.svg" alt="Token"><img src="favicons/token.svg" alt="Token"></h1>
    <p>
        A pure Javascript tokenizer running in your browser that can load <code>tokenizer.json</code> and
        <code>tokenizer_config.json</code> from any repository on Huggingface. You can use it to count tokens and
        compare how different large language model vocabularies work. It's also useful for debugging prompt templates.
        If you are wondering why are there so many models under Xenova, it's because they work for HuggingFace and
        re-upload just the tokenizers, so it's possible to load them without agreeing to model licences.
    </p>
    <!-- TODO: take text from URL params? -->
    <textarea id="textInput" name="textInput" autofocus placeholder="Enter the text you want to tokenize"
        style="height: 5em;">
[INST] <<SYS>>
You are a friendly Llama.
<</SYS>>

Do you spit at people?[/INST]</textarea>
    <ul id="models"></ul>
    <div id="addModel">
        <!-- TODO: add styling -->
        <input placeholder="01-ai/Yi-34B" />
        <button>Add tokenizer from HuggingFace</button>
    </div>
</body>
<script type="module" async src="tokenizer.js"></script>

</html>